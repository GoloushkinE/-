{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive #подключение гугл диска\n",
        "drive.mount ('/content/drive/')\n",
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV407xR2VwGJ",
        "outputId": "498b88d2-9043-4686-d9b6-eca4b31cd526"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dwT-WWGwBa4S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # Импортировал библиотеку pandas\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt # Импортировал библиотеку pyplot\n",
        "import numpy as np # Импортировал библиотеку numpy\n",
        "\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "\n",
        "# Загрузим данные из файла\n",
        "data = pd.read_csv('/content/drive/MyDrive/Laptop_price.csv')\n",
        "\n",
        "# Выберем столбец Price в качестве целевого\n",
        "y = data['Price']\n",
        "\n",
        "# Удалим столбец Price из X\n",
        "X = data.drop('Price', axis=1)\n",
        "\n",
        "# Сделаем сплит\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_columns = list(X_train.select_dtypes(exclude=['object']))\n",
        "num_columns"
      ],
      "metadata": {
        "id": "u0vSSDHVLNwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1141d34-fdd2-4f0d-81ad-4cfe78d5e462"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Processor_Speed', 'RAM_Size', 'Storage_Capacity', 'Screen_Size', 'Weight']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_columns = list(X_train.select_dtypes(include=['object']))\n",
        "cat_columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWQp44ezMfKJ",
        "outputId": "4ada4705-54a4-45d5-c3f1-60697c5f70b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Brand']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical = Pipeline(steps=[\n",
        "    (\"simple_imputer\", SimpleImputer()), #подбор стратегии по заполнению пропущенных значений\n",
        "    (\"power_transform\", PowerTransformer()), #приведение данных к нормальному распределению\n",
        "    ('Scaler', StandardScaler())#стандартизирует данные\n",
        "])"
      ],
      "metadata": {
        "id": "quaf5F8ENraQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = Pipeline(steps=[\n",
        "    (\"simple_imputer\", SimpleImputer(strategy='')),\n",
        "    (\"OneHotEncoder\", OneHotEncoder(handle_unknown='ignore', # drop = ['first', 'if_binary']\n",
        "                                    sparse_output=False))#\n",
        "\n",
        "    ])"
      ],
      "metadata": {
        "id": "ZvHTHqdDQMYe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = ColumnTransformer([\n",
        "    (\"numerical\", numerical, num_columns),\n",
        "    (\"categorical\", categorical, cat_columns)\n",
        "])"
      ],
      "metadata": {
        "id": "0rY1Gd45RnVt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline(steps=[\n",
        "    (\"ct\", ct),\n",
        "    (\"XGBRegressor\", XGBRegressor(booster=None, callbacks=None,\n",
        "                                  gamma=None, grow_policy=None,\n",
        "                                  importance_type=None, interaction_constraints=None, learning_rate=None,\n",
        "                                  max_bin=None, max_cat_threshold=None, random_state=None))\n",
        "])"
      ],
      "metadata": {
        "id": "fghj48THSqeL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid={\n",
        "    'XGBRegressor__n_estimators':[50],\n",
        "    'XGBRegressor__learning_rate':[0,1],\n",
        "    'ct__numerical': [StandardScaler(),RobustScaler()]# в пайплайне есть инструмент позволяющий оптимизировать подбор нужных гиперпараметров.\n",
        "    #GridSearch - это очень мощный инструмент для автоматического подбирания параметров для моделей машинного обучения.\n",
        "    #GridSearchCV находит наилучшие параметры, путем обычного перебора: он создает модель для каждой возможной комбинации параметров.\n",
        "    #Важно отметить, что такой подход может быть весьма времязатратным\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "07-UkgeeS-UT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GridSearchCV(pipe, param_grid, verbose=3)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "clf.score(X_test, y_test)\n",
        "\n",
        "model=clf.best_estimator_\n",
        "clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G0sPUC16T-s2",
        "outputId": "b43edf3f-7555-41f4-89bd-8ca5b1dc7c71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV 1/5] END XGBRegressor__learning_rate=0, XGBRegressor__n_estimators=60, ct__numerical=StandardScaler();, score=nan total time=   0.0s\n",
            "[CV 2/5] END XGBRegressor__learning_rate=0, XGBRegressor__n_estimators=60, ct__numerical=StandardScaler();, score=nan total time=   0.0s\n",
            "[CV 3/5] END XGBRegressor__learning_rate=0, XGBRegressor__n_estimators=60, ct__numerical=StandardScaler();, score=nan total time=   0.0s\n",
            "[CV 4/5] END XGBRegressor__learning_rate=0, XGBRegressor__n_estimators=60, ct__numerical=StandardScaler();, score=nan total time=   0.0s\n",
            "[CV 5/5] END XGBRegressor__learning_rate=0, XGBRegressor__n_estimators=60, ct__numerical=StandardScaler();, score=nan total time=   0.0s\n",
            "[CV 1/5] END XGBRegressor__learning_rate=0, XGBRegressor__n_estimators=60, ct__numerical=RobustScaler();, score=nan total time=   0.0s\n",
            "[CV 2/5] END XGBRegressor__learning_rate=0, XGBRegressor__n_estimators=60, ct__numerical=RobustScaler();, score=nan total time=   0.0s\n",
            "[CV 3/5] END XGBRegressor__learning_rate=0, XGBRegressor__n_estimators=60, ct__numerical=RobustScaler();, score=nan total time=   0.0s\n",
            "[CV 4/5] END XGBRegressor__learning_rate=0, XGBRegressor__n_estimators=60, ct__numerical=RobustScaler();, score=nan total time=   0.0s\n",
            "[CV 5/5] END XGBRegressor__learning_rate=0, XGBRegressor__n_estimators=60, ct__numerical=RobustScaler();, score=nan total time=   0.0s\n",
            "[CV 1/5] END XGBRegressor__learning_rate=1, XGBRegressor__n_estimators=60, ct__numerical=StandardScaler();, score=nan total time=   0.0s\n",
            "[CV 2/5] END XGBRegressor__learning_rate=1, XGBRegressor__n_estimators=60, ct__numerical=StandardScaler();, score=nan total time=   0.0s\n",
            "[CV 3/5] END XGBRegressor__learning_rate=1, XGBRegressor__n_estimators=60, ct__numerical=StandardScaler();, score=nan total time=   0.0s\n",
            "[CV 4/5] END XGBRegressor__learning_rate=1, XGBRegressor__n_estimators=60, ct__numerical=StandardScaler();, score=nan total time=   0.0s\n",
            "[CV 5/5] END XGBRegressor__learning_rate=1, XGBRegressor__n_estimators=60, ct__numerical=StandardScaler();, score=nan total time=   0.0s\n",
            "[CV 1/5] END XGBRegressor__learning_rate=1, XGBRegressor__n_estimators=60, ct__numerical=RobustScaler();, score=nan total time=   0.0s\n",
            "[CV 2/5] END XGBRegressor__learning_rate=1, XGBRegressor__n_estimators=60, ct__numerical=RobustScaler();, score=nan total time=   0.0s\n",
            "[CV 3/5] END XGBRegressor__learning_rate=1, XGBRegressor__n_estimators=60, ct__numerical=RobustScaler();, score=nan total time=   0.0s\n",
            "[CV 4/5] END XGBRegressor__learning_rate=1, XGBRegressor__n_estimators=60, ct__numerical=RobustScaler();, score=nan total time=   0.0s\n",
            "[CV 5/5] END XGBRegressor__learning_rate=1, XGBRegressor__n_estimators=60, ct__numerical=RobustScaler();, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 20 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n    result = self._fit_transform(X, y, _fit_transform_one)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n    return super().__call__(iterable_with_config)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 881, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 380, in fit\n    self._validate_params()\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'strategy' parameter of SimpleImputer must be a str among {'constant', 'most_frequent', 'median', 'mean'}. Got '' instead.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-efb9fcd10a79>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 20 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n    result = self._fit_transform(X, y, _fit_transform_one)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n    return super().__call__(iterable_with_config)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 881, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 380, in fit\n    self._validate_params()\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'strategy' parameter of SimpleImputer must be a str among {'constant', 'most_frequent', 'median', 'mean'}. Got '' instead.\n"
          ]
        }
      ]
    }
  ]
}